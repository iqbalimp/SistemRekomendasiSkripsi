{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data baru ditemukan, melakukan proses NLP Cleaning\n",
      "Proses Cleaning pada data telah selesai, data telah di simpan\n",
      "========== MENU ==========\n",
      "1. Data Skripsi\n",
      "2. Grafik Skripsi di Sistem Informasi\n",
      "3. Rekomendasi Skripsi Berdasarkan Abstrak\n",
      "0. Keluar\n",
      "Terima kasih! Program telah berakhir.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "\n",
    "# Fungsi untuk membersihkan teks\n",
    "def text_clean(text):\n",
    "    factory = StemmerFactory()\n",
    "    stemmer = factory.create_stemmer()\n",
    "    sastrawi = StopWordRemoverFactory()\n",
    "    stopworda = sastrawi.get_stop_words()\n",
    "    clean_spcl = re.compile('[/(){}\\[\\]\\|@,;]')\n",
    "    clean_symbol = re.compile('[^0-9a-z #+_]')\n",
    "    text = text.lower()\n",
    "    text = clean_spcl.sub(' ', text)\n",
    "    text = clean_symbol.sub('', text)\n",
    "    text = stemmer.stem(text)\n",
    "    text = ' '.join(word for word in text.split() if word not in stopworda)\n",
    "    return text\n",
    "\n",
    "def cleaning_judulabstract():\n",
    "    # Pengecekan data baru pada \n",
    "    try:\n",
    "        cleaned_data_skripsi = pd.read_csv('cleaned_data_skripsi.csv')\n",
    "    except FileNotFoundError:\n",
    "        cleaned_data_skripsi = pd.DataFrame()  # Jika file tidak ada, mulai dengan DataFrame kosong\n",
    "    \n",
    "    # Memuat data terbaru\n",
    "    # data_skripsi_baru = pd.read_excel('data_skripsi_librarytrunojoyo.xlsx', sheet_name='skripsi', usecols='A:I')\n",
    "    data_skripsi_baru = pd.read_excel('data_skripsi_librarytrunojoyo.xlsx', sheet_name='skripsi', usecols='A:I', engine='openpyxl')\n",
    "    data_skripsi_baru = data_skripsi_baru[data_skripsi_baru['Abstrak'].notnull() & data_skripsi_baru['Judul Skripsi'].notnull()]\n",
    "\n",
    "\n",
    "    #Cek apakah ada baris data baru di masukan kedalam excel\n",
    "    if not cleaned_data_skripsi.empty:\n",
    "        data_baru = data_skripsi_baru[~data_skripsi_baru['Judul Skripsi'].isin(cleaned_data_skripsi['Judul Skripsi'])]\n",
    "    else:\n",
    "        data_baru = data_skripsi_baru\n",
    "    \n",
    "    #Jika tidak ada rows data skripsi baru, maka melakukan cleaning\n",
    "    if not data_baru.empty:\n",
    "        print(\"Data baru ditemukan, melakukan proses NLP Cleaning\")\n",
    "        data_baru['cleaned_judul'] = data_baru['Judul Skripsi'].apply(text_clean)\n",
    "        data_baru['cleaned_abstrak'] = data_baru['Abstrak'].apply(text_clean)\n",
    "\n",
    "        updated_cleaned_data = pd.concat([cleaned_data_skripsi, data_baru], ignore_index=True)\n",
    "        updated_cleaned_data.to_csv('cleaned_data_skripsi.csv', index=False)\n",
    "\n",
    "        print(\"Proses Cleaning pada data telah selesai, data telah di simpan\")\n",
    "    else:\n",
    "        print(\"Tidak ada rows data skripsi baru, cleaning tidak diperlukan\")\n",
    "\n",
    "# Fungsi untuk menampilkan data skripsi\n",
    "def display_data_skripsi():\n",
    "    data_skripsi = pd.read_csv('cleaned_data_skripsi.csv', sheet_name='skripsi', usecols='A:I')\n",
    "    data_skripsi = data_skripsi[data_skripsi['Abstrak'].notnull()]\n",
    "    data_skripsi.reset_index(drop=True, inplace=True)\n",
    "    print(data_skripsi[['Judul Skripsi', 'Abstrak']])\n",
    "\n",
    "# Fungsi untuk menampilkan data skripsi\n",
    "def display_grafik_skripsi():\n",
    "    # Muat data yang sudah dibersihkan\n",
    "    data_skripsi = pd.read_csv('cleaned_data_skripsi.csv')\n",
    "\n",
    "    # Hitung jumlah kemunculan setiap dosen sebagai Dosen Pembimbing 1\n",
    "    dospem1_count = data_skripsi['Dospem1'].value_counts()\n",
    "\n",
    "    # Hitung jumlah kemunculan setiap dosen sebagai Dosen Pembimbing 2\n",
    "    dospem2_count = data_skripsi['Dospem2'].value_counts()\n",
    "\n",
    "    # Plot grafik batang untuk Dosen Pembimbing 1\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    bars1 = dospem1_count.plot(kind='bar', color='lightcoral')\n",
    "    \n",
    "    # Judul dan label sumbu untuk grafik Dosen Pembimbing 1\n",
    "    plt.title('Distribusi Dosen Pembimbing 1', fontsize=14)\n",
    "    plt.xlabel('Nama Dosen Pembimbing 1', fontsize=12)\n",
    "    plt.ylabel('Jumlah Skripsi Dibimbing', fontsize=12)\n",
    "\n",
    "    # Menambahkan keterangan jumlah skripsi di atas setiap batang untuk Dospem 1\n",
    "    for index, value in enumerate(dospem1_count):\n",
    "        plt.text(index, value + 0.1, str(value), ha='center', fontsize=10)\n",
    "\n",
    "    # Tampilkan grafik Dospem 1\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Plot grafik batang untuk Dosen Pembimbing 2\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    bars2 = dospem2_count.plot(kind='bar', color='lightblue')\n",
    "\n",
    "    # Judul dan label sumbu untuk grafik Dosen Pembimbing 2\n",
    "    plt.title('Distribusi Dosen Pembimbing 2', fontsize=14)\n",
    "    plt.xlabel('Nama Dosen Pembimbing 2', fontsize=12)\n",
    "    plt.ylabel('Jumlah Skripsi Dibimbing', fontsize=12)\n",
    "\n",
    "    # Menambahkan keterangan jumlah skripsi di atas setiap batang untuk Dospem 2\n",
    "    for index, value in enumerate(dospem2_count):\n",
    "        plt.text(index, value + 0.1, str(value), ha='center', fontsize=10)\n",
    "\n",
    "    # Tampilkan grafik Dospem 2\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def display_wordcloud_dospem():\n",
    "    # Muat data yang sudah dibersihkan\n",
    "    data_skripsi = pd.read_csv('cleaned_data_skripsi.csv')\n",
    "    # Hitung jumlah kemunculan setiap dosen sebagai Dospem1 dan Dospem2\n",
    "    dospem1_count = data_skripsi['Dospem1'].value_counts()\n",
    "    dospem2_count = data_skripsi['Dospem2'].value_counts()\n",
    "    combined_dospem = dospem1_count.add(dospem2_count, fill_value=0)\n",
    "\n",
    "    # Buat WordCloud\n",
    "    wordcloud = WordCloud(width=800, height=400, background_color='white').generate_from_frequencies(combined_dospem)\n",
    "\n",
    "    # Plot WordCloud\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis('off')\n",
    "    plt.title(\"Distribusi Dosen Pembimbing (Dospem1 dan Dospem2) - WordCloud\", fontsize=16)\n",
    "    plt.show()\n",
    "\n",
    "# Fungsi untuk melakukan rekomendasi skripsi hanya berdasarkan abstrak\n",
    "def recommend_skripsi():\n",
    "    data_skripsi = pd.read_csv('cleaned_data_skripsi.csv')\n",
    "    \n",
    "    # Membuat TF-IDF untuk judul dan abstrak\n",
    "    tfidf_vectorizer_judul = TfidfVectorizer(analyzer='word', ngram_range=(1, 3), min_df=0, max_df=0.85, sublinear_tf=True)\n",
    "    tfidf_vectorizer_abstrak = TfidfVectorizer(analyzer='word', ngram_range=(1, 3), min_df=0, max_df=0.85, sublinear_tf=True)\n",
    "    \n",
    "    # Membuat matriks TF-IDF\n",
    "    tfidf_matrix_judul = tfidf_vectorizer_judul.fit_transform(data_skripsi['cleaned_judul'])\n",
    "    tfidf_matrix_abstrak = tfidf_vectorizer_abstrak.fit_transform(data_skripsi['cleaned_abstrak'])\n",
    "\n",
    "    # Fungsi untuk menghitung rekomendasi\n",
    "    def recommendations(keyword, top=10):\n",
    "        rekomendasi = []\n",
    "        cleaned_keyword = text_clean(keyword)\n",
    "\n",
    "        # TF-IDF untuk input keyword\n",
    "        tfidf_keyword_judul = tfidf_vectorizer_judul.transform([cleaned_keyword])\n",
    "        tfidf_keyword_abstrak = tfidf_vectorizer_abstrak.transform([cleaned_keyword])\n",
    "        \n",
    "        # Menghitung cosine similarity\n",
    "        scores_judul = cosine_similarity(tfidf_matrix_judul, tfidf_keyword_judul).flatten()\n",
    "        scores_abstrak = cosine_similarity(tfidf_matrix_abstrak, tfidf_keyword_abstrak).flatten()\n",
    "        \n",
    "        # Menjumlahkan skor dari judul dan abstrak\n",
    "        combined_scores = scores_judul + scores_abstrak\n",
    "        \n",
    "        # Mengurutkan berdasarkan skor tertinggi\n",
    "        sorted_indexes = np.argsort(combined_scores)[::-1]\n",
    "        \n",
    "        # Mendapatkan rekomendasi berdasarkan top skor\n",
    "        for i in sorted_indexes[:top]:\n",
    "            judul = data_skripsi.iloc[i]['Judul Skripsi']\n",
    "            link = data_skripsi.iloc[i]['Link Skripsi']\n",
    "            penulis = data_skripsi.iloc[i]['Penulis']\n",
    "            abstrak = data_skripsi.iloc[i]['Abstrak']\n",
    "            score = combined_scores[i]\n",
    "            rekomendasi.append((judul, link, penulis, abstrak, score))\n",
    "        \n",
    "        return rekomendasi\n",
    "\n",
    "    # Input keyword dari user\n",
    "    keyword = input(\"Masukkan keyword: \")\n",
    "    jumlah_rekomendasi = int(input(\"Masukkan jumlah rekomendasi: \"))\n",
    "    \n",
    "    # Mendapatkan rekomendasi\n",
    "    hasil_rekomendasi = recommendations(keyword, jumlah_rekomendasi)\n",
    "    \n",
    "    # Menampilkan hasil\n",
    "    print(f\"Hasil rekomendasi skripsi yang mungkin Anda sukai berdasarkan '{keyword}':\")\n",
    "    for index, (judul, link, penulis, abstrak, score) in enumerate(hasil_rekomendasi, 1):\n",
    "        print(f\"\\nRekomendasi ke-{index}:\")\n",
    "        print(f\"Judul: {judul}\")\n",
    "        print(f\"Link: {link}\")\n",
    "        print(f\"Penulis: {penulis}\")\n",
    "        print(f\"Abstrak: {abstrak}\")\n",
    "        print(f\"Score: {score:.4f}\")\n",
    "\n",
    "# Menu\n",
    "def main():\n",
    "    # Jalankan cleaning abstract pertama kali saat sistem dimulai\n",
    "    cleaning_judulabstract()\n",
    "\n",
    "    while True:\n",
    "        print(\"========== MENU ==========\")\n",
    "        print(\"1. Data Skripsi\")\n",
    "        print(\"2. Grafik Skripsi di Sistem Informasi\")\n",
    "        print(\"3. Rekomendasi Skripsi Berdasarkan Abstrak\")\n",
    "        print(\"0. Keluar\")\n",
    "        choice = input(\"Pilih menu: \")\n",
    "\n",
    "        if choice == \"1\":\n",
    "            print(\"\\n----- Data Skripsi -----\")\n",
    "            display_data_skripsi()\n",
    "            print(\"-----------------------\\n\")\n",
    "        elif choice == \"2\":\n",
    "            print(\"\\n----- Grafik Skripsi di Sistem Informasi -----\")\n",
    "            display_grafik_skripsi()\n",
    "            print(\"-----------------------------------\\n\")\n",
    "        elif choice == \"3\":\n",
    "            print(\"\\n----- Rekomendasi Skripsi Berdasarkan Abstrak -----\")\n",
    "            recommend_skripsi()\n",
    "            print(\"-----------------------------\\n\")\n",
    "        elif choice == \"0\":\n",
    "            print(\"Terima kasih! Program telah berakhir.\")\n",
    "            break\n",
    "        else:\n",
    "            print(\"Pilihan tidak valid. Silakan pilih menu yang tersedia\")\n",
    "\n",
    "\n",
    "# Jalankan program\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
